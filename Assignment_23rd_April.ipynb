{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRxdNuc7mDGi"
      },
      "outputs": [],
      "source": [
        "# Task1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all sklearn datasets"
      ],
      "metadata": {
        "id": "TZ3fTYHmmNXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Import specific model library (e.g., sklearn.linear_model for linear regression)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "MDzo1fZCmNaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2"
      ],
      "metadata": {
        "id": "N7AMlh1DmNfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the data into features and labels."
      ],
      "metadata": {
        "id": "aE2hUN9SmNl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import  load_iris, load_diabetes, load_digits\n",
        "from sklearn.datasets import load_linnerud, load_wine, load_breast_cancer, fetch_olivetti_faces\n",
        "from sklearn.datasets import fetch_20newsgroups, fetch_lfw_people, fetch_covtype, fetch_california_housing\n",
        "\n",
        "# Load datasets\n",
        "# boston = load_boston()\n",
        "iris = load_iris()\n",
        "diabetes = load_diabetes()\n",
        "digits = load_digits()\n",
        "linnerud = load_linnerud()\n",
        "wine = load_wine()\n",
        "breast_cancer = load_breast_cancer()\n",
        "olivetti_faces = fetch_olivetti_faces()\n",
        "newsgroups = fetch_20newsgroups()\n",
        "lfw_people = fetch_lfw_people()\n",
        "covtype = fetch_covtype()\n",
        "california_housing = fetch_california_housing()\n",
        "\n",
        "# List of loaded datasets\n",
        "datasets = {\n",
        "    # 'boston': boston,\n",
        "    'iris': iris,\n",
        "    'diabetes': diabetes,\n",
        "    'digits': digits,\n",
        "    'linnerud': linnerud,\n",
        "    'wine': wine,\n",
        "    'breast_cancer': breast_cancer,\n",
        "    'olivetti_faces': olivetti_faces,\n",
        "    'newsgroups': newsgroups,\n",
        "    'lfw_people': lfw_people,\n",
        "    'covtype': covtype,\n",
        "    'california_housing': california_housing\n",
        "}\n",
        "\n",
        "# Print keys of the loaded datasets\n",
        "print(\"Available datasets:\")\n",
        "for key in datasets:\n",
        "    print(key)\n"
      ],
      "metadata": {
        "id": "H0PMP4rcmNcp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e044968-018a-4282-e825-b4625350f747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading Olivetti faces from https://ndownloader.figshare.com/files/5976027 to /root/scikit_learn_data\n",
            "Available datasets:\n",
            "iris\n",
            "diabetes\n",
            "digits\n",
            "linnerud\n",
            "wine\n",
            "breast_cancer\n",
            "olivetti_faces\n",
            "newsgroups\n",
            "lfw_people\n",
            "covtype\n",
            "california_housing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "# Features (X): Sepal length, sepal width, petal length, and petal width\n",
        "X = iris.data\n",
        "\n",
        "# Labels (y): Species (0 for setosa, 1 for versicolor, 2 for virginica)\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shapes of the splits\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n"
      ],
      "metadata": {
        "id": "6LB5pi_MmNz9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbeff909-c2fd-4442-de2e-eb0d4d9c303f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (120, 4), y_train shape: (120,)\n",
            "X_test shape: (30, 4), y_test shape: (30,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into features and labels for each dataset\n",
        "\n",
        "iris_features, iris_labels = iris.data, iris.target\n",
        "diabetes_features, diabetes_labels = diabetes.data, diabetes.target\n",
        "digits_features, digits_labels = digits.data, digits.target\n",
        "linnerud_features, linnerud_labels = linnerud.data, linnerud.target\n",
        "wine_features, wine_labels = wine.data, wine.target\n",
        "breast_cancer_features, breast_cancer_labels = breast_cancer.data, breast_cancer.target\n",
        "olivetti_faces_data, olivetti_faces_labels = olivetti_faces.data, olivetti_faces.target\n",
        "newsgroups_data, newsgroups_labels = newsgroups.data, newsgroups.target\n",
        "lfw_people_data, lfw_people_labels = lfw_people.data, lfw_people.target\n",
        "covtype_data, covtype_labels = covtype.data, covtype.target\n",
        "california_housing_data, california_housing_labels = california_housing.data, california_housing.target\n"
      ],
      "metadata": {
        "id": "bh7R6wZKmNuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3"
      ],
      "metadata": {
        "id": "p4kJQkg6mN3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You are required to perform preprocessing including scaling and encoding."
      ],
      "metadata": {
        "id": "m85kaeSTmN6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load a specific dataset (e.g., Iris)\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "# Define preprocessing steps\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), [0, 1, 2, 3]),  # Scale numeric features\n",
        "        ('cat', OneHotEncoder(), [])  # No categorical features in this dataset\n",
        "    ])\n",
        "\n",
        "# Define the pipeline\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
        "\n",
        "# Preprocess the data\n",
        "X_processed = pipeline.fit_transform(iris.data)\n",
        "y = iris.target\n",
        "\n",
        "# Print preprocessed features shape\n",
        "print(\"Preprocessed features shape:\", X_processed.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdMDeIENJOEA",
        "outputId": "e1fb12f8-275d-43d3-9fdd-c029795fb06b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed features shape: (150, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 4"
      ],
      "metadata": {
        "id": "KCFAYB_zMVMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#: Perform all types of SVM classifications on the above prepared Dataset(apply that to any four datasets)."
      ],
      "metadata": {
        "id": "OYnodAPAOdMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a pipeline with preprocessing and SVM classifier\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('svm', SVC(kernel='linear'))  # Linear kernel\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy with linear kernel:\", accuracy)\n",
        "\n",
        "# Try different SVM kernels\n",
        "kernels = ['rbf', 'poly', 'sigmoid']\n",
        "\n",
        "for kernel in kernels:\n",
        "    # Define a pipeline with preprocessing and SVM classifier\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('svm', SVC(kernel=kernel))\n",
        "    ])\n",
        "\n",
        "    # Train the model\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy with {kernel} kernel:\", accuracy)\n"
      ],
      "metadata": {
        "id": "emJDU2skOhWO",
        "outputId": "12919158-58e4-4398-c685-290717d7abef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with linear kernel: 0.9666666666666667\n",
            "Accuracy with rbf kernel: 1.0\n",
            "Accuracy with poly kernel: 0.9666666666666667\n",
            "Accuracy with sigmoid kernel: 0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 4\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a pipeline with preprocessing and SVM classifier\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('svm', SVC(kernel='linear'))  # Linear kernel\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy with linear kernel:\", accuracy)\n",
        "\n",
        "# Try different SVM kernels\n",
        "kernels = ['rbf', 'poly', 'sigmoid']\n",
        "\n",
        "for kernel in kernels:\n",
        "    # Define a pipeline with preprocessing and SVM classifier\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('svm', SVC(kernel=kernel))\n",
        "    ])\n",
        "\n",
        "    # Train the model\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy with {kernel} kernel:\", accuracy)\n",
        "\n",
        "# Task 5\n",
        "# Apply the same procedure to three other datasets of your choice.\n",
        "\n",
        "# Load the Diabetes dataset\n",
        "diabetes = datasets.load_diabetes()\n",
        "X = diabetes.data\n",
        "y = diabetes.target\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a pipeline with preprocessing and SVM classifier\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('svm', SVC(kernel='linear'))  # Linear kernel\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy with linear kernel:\", accuracy)\n",
        "\n",
        "# Try different SVM kernels\n",
        "kernels = ['rbf', 'poly', 'sigmoid']\n",
        "\n",
        "for kernel in kernels:\n",
        "    # Define a pipeline with preprocessing and SVM classifier\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('svm', SVC(kernel=kernel))\n",
        "    ])\n",
        "\n",
        "    # Train the model\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy with {kernel} kernel:\", accuracy)\n",
        "\n",
        "# Load the Digits dataset\n",
        "digits = datasets.load_digits()\n",
        "X = digits.data\n",
        "y = digits.target\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a pipeline with preprocessing and SVM classifier\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('svm', SVC(kernel='linear'))  # Linear kernel\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy with linear kernel:\", accuracy)\n",
        "\n",
        "# Try different SVM kernels\n",
        "kernels = ['rbf', 'poly', 'sigmoid']\n",
        "\n",
        "for kernel in kernels:\n",
        "    # Define a pipeline with preprocessing and SVM classifier\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('svm', SVC(kernel=kernel))\n",
        "    ])\n",
        "\n",
        "    # Train the model\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy with {kernel} kernel:\", accuracy)\n"
      ],
      "metadata": {
        "id": "id_AjeRSP69g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "909417e1-0565-41b5-e042-026cf775fa95"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with linear kernel: 0.9666666666666667\n",
            "Accuracy with rbf kernel: 1.0\n",
            "Accuracy with poly kernel: 0.9666666666666667\n",
            "Accuracy with sigmoid kernel: 0.9\n",
            "Accuracy with linear kernel: 0.011235955056179775\n",
            "Accuracy with rbf kernel: 0.0\n",
            "Accuracy with poly kernel: 0.0\n",
            "Accuracy with sigmoid kernel: 0.0\n",
            "Accuracy with linear kernel: 0.975\n",
            "Accuracy with rbf kernel: 0.9805555555555555\n",
            "Accuracy with poly kernel: 0.9638888888888889\n",
            "Accuracy with sigmoid kernel: 0.9277777777777778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 5"
      ],
      "metadata": {
        "id": "-i0-Qa9VJyQ4"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display confusion matrix and generate report of f1-score, recall and precision."
      ],
      "metadata": {
        "id": "cJlcG0g6J0Va"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a pipeline with preprocessing and SVM classifier\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('svm', SVC(kernel='linear'))  # Linear kernel\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy with linear kernel:\", accuracy)\n",
        "\n",
        "# Display confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred, target_names=iris.target_names)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Try different SVM kernels\n",
        "kernels = ['rbf', 'poly', 'sigmoid']\n",
        "\n",
        "for kernel in kernels:\n",
        "    # Define a pipeline with preprocessing and SVM classifier\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('svm', SVC(kernel=kernel))\n",
        "    ])\n",
        "\n",
        "    # Train the model\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"\\nAccuracy with {kernel} kernel:\", accuracy)\n",
        "\n",
        "    # Display confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(y_test, y_pred, target_names=iris.target_names)\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(report)\n"
      ],
      "metadata": {
        "id": "B-S1bz1bQbdY",
        "outputId": "157f6ef3-028d-4da0-a259-3352a18523b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with linear kernel: 0.9666666666666667\n",
            "\n",
            "Confusion Matrix:\n",
            "[[10  0  0]\n",
            " [ 0  8  1]\n",
            " [ 0  0 11]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      0.89      0.94         9\n",
            "   virginica       0.92      1.00      0.96        11\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.96      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n",
            "\n",
            "Accuracy with rbf kernel: 1.0\n",
            "\n",
            "Confusion Matrix:\n",
            "[[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      1.00      1.00         9\n",
            "   virginica       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "\n",
            "Accuracy with poly kernel: 0.9666666666666667\n",
            "\n",
            "Confusion Matrix:\n",
            "[[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  1 10]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       0.90      1.00      0.95         9\n",
            "   virginica       1.00      0.91      0.95        11\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.97      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n",
            "\n",
            "Accuracy with sigmoid kernel: 0.9\n",
            "\n",
            "Confusion Matrix:\n",
            "[[10  0  0]\n",
            " [ 0  7  2]\n",
            " [ 0  1 10]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       0.88      0.78      0.82         9\n",
            "   virginica       0.83      0.91      0.87        11\n",
            "\n",
            "    accuracy                           0.90        30\n",
            "   macro avg       0.90      0.90      0.90        30\n",
            "weighted avg       0.90      0.90      0.90        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 6"
      ],
      "metadata": {
        "id": "jc6VrdG3KIy0"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load dataset of Mushroom.csv."
      ],
      "metadata": {
        "id": "0IWd2quCKJEq"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load Mushroom dataset from CSV\n",
        "mushroom_df = pd.read_csv('/content/mushrooms.csv')\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(mushroom_df.head())\n"
      ],
      "metadata": {
        "id": "GUg-xknfF4CU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13d880fc-e106-4fb0-e668-52444647c4c9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
            "0     p         x           s         n       t    p               f   \n",
            "1     e         x           s         y       t    a               f   \n",
            "2     e         b           s         w       t    l               f   \n",
            "3     p         x           y         w       t    p               f   \n",
            "4     e         x           s         g       f    n               f   \n",
            "\n",
            "  gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
            "0            c         n          k  ...                        s   \n",
            "1            c         b          k  ...                        s   \n",
            "2            c         b          n  ...                        s   \n",
            "3            c         n          n  ...                        s   \n",
            "4            w         b          k  ...                        s   \n",
            "\n",
            "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
            "0                      w                      w         p          w   \n",
            "1                      w                      w         p          w   \n",
            "2                      w                      w         p          w   \n",
            "3                      w                      w         p          w   \n",
            "4                      w                      w         p          w   \n",
            "\n",
            "  ring-number ring-type spore-print-color population habitat  \n",
            "0           o         p                 k          s       u  \n",
            "1           o         p                 n          n       g  \n",
            "2           o         p                 n          n       m  \n",
            "3           o         p                 k          s       u  \n",
            "4           o         e                 n          a       g  \n",
            "\n",
            "[5 rows x 23 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 7"
      ],
      "metadata": {
        "id": "BYZM1Vk5F34O"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform preprocessing.\n"
      ],
      "metadata": {
        "id": "BbYrUbd5F37U"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load Mushroom dataset from CSV\n",
        "mushroom_df = pd.read_csv('/content/mushrooms.csv')\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(mushroom_df.head())\n"
      ],
      "metadata": {
        "id": "mSY0bdh0QxeB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa8c92ed-b451-4d66-d1c8-b8b55598b3c4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
            "0     p         x           s         n       t    p               f   \n",
            "1     e         x           s         y       t    a               f   \n",
            "2     e         b           s         w       t    l               f   \n",
            "3     p         x           y         w       t    p               f   \n",
            "4     e         x           s         g       f    n               f   \n",
            "\n",
            "  gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
            "0            c         n          k  ...                        s   \n",
            "1            c         b          k  ...                        s   \n",
            "2            c         b          n  ...                        s   \n",
            "3            c         n          n  ...                        s   \n",
            "4            w         b          k  ...                        s   \n",
            "\n",
            "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
            "0                      w                      w         p          w   \n",
            "1                      w                      w         p          w   \n",
            "2                      w                      w         p          w   \n",
            "3                      w                      w         p          w   \n",
            "4                      w                      w         p          w   \n",
            "\n",
            "  ring-number ring-type spore-print-color population habitat  \n",
            "0           o         p                 k          s       u  \n",
            "1           o         p                 n          n       g  \n",
            "2           o         p                 n          n       m  \n",
            "3           o         p                 k          s       u  \n",
            "4           o         e                 n          a       g  \n",
            "\n",
            "[5 rows x 23 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load Mushroom dataset from CSV\n",
        "mushroom_df = pd.read_csv('/content/mushrooms.csv')\n",
        "\n",
        "# Encode categorical variables using LabelEncoder\n",
        "label_encoders = {}\n",
        "for column in mushroom_df.columns:\n",
        "    encoder = LabelEncoder()\n",
        "    mushroom_df[column] = encoder.fit_transform(mushroom_df[column])\n",
        "    label_encoders[column] = encoder\n",
        "\n",
        "# Separate features and labels\n",
        "X = mushroom_df.drop('class', axis=1)\n",
        "y = mushroom_df['class']\n",
        "\n",
        "# Display the preprocessed dataset\n",
        "print(X.head())\n",
        "print(y.head())\n"
      ],
      "metadata": {
        "id": "qzkohAXUQbbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f714143-ee53-4a94-cb3f-c52491719a7f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
            "0          5            2          4        1     6                1   \n",
            "1          5            2          9        1     0                1   \n",
            "2          0            2          8        1     3                1   \n",
            "3          5            3          8        1     6                1   \n",
            "4          5            2          3        0     5                1   \n",
            "\n",
            "   gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
            "0             0          1           4            0  ...   \n",
            "1             0          0           4            0  ...   \n",
            "2             0          0           5            0  ...   \n",
            "3             0          1           5            0  ...   \n",
            "4             1          0           4            1  ...   \n",
            "\n",
            "   stalk-surface-below-ring  stalk-color-above-ring  stalk-color-below-ring  \\\n",
            "0                         2                       7                       7   \n",
            "1                         2                       7                       7   \n",
            "2                         2                       7                       7   \n",
            "3                         2                       7                       7   \n",
            "4                         2                       7                       7   \n",
            "\n",
            "   veil-type  veil-color  ring-number  ring-type  spore-print-color  \\\n",
            "0          0           2            1          4                  2   \n",
            "1          0           2            1          4                  3   \n",
            "2          0           2            1          4                  3   \n",
            "3          0           2            1          4                  2   \n",
            "4          0           2            1          0                  3   \n",
            "\n",
            "   population  habitat  \n",
            "0           3        5  \n",
            "1           2        1  \n",
            "2           2        3  \n",
            "3           3        5  \n",
            "4           0        1  \n",
            "\n",
            "[5 rows x 22 columns]\n",
            "0    1\n",
            "1    0\n",
            "2    0\n",
            "3    1\n",
            "4    0\n",
            "Name: class, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 8"
      ],
      "metadata": {
        "id": "ySZwFLUaQbf8"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# As this is a classification problem you are required to perform classification on all available algorithms in sci-kit."
      ],
      "metadata": {
        "id": "nlWf9cLMQbjC"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Load Mushroom dataset from CSV\n",
        "mushroom_df = pd.read_csv('/content/mushrooms.csv')\n",
        "\n",
        "# Encode categorical variables using LabelEncoder\n",
        "label_encoders = {}\n",
        "for column in mushroom_df.columns:\n",
        "    encoder = LabelEncoder()\n",
        "    mushroom_df[column] = encoder.fit_transform(mushroom_df[column])\n",
        "    label_encoders[column] = encoder\n",
        "\n",
        "# Separate features and labels\n",
        "X = mushroom_df.drop('class', axis=1)\n",
        "y = mushroom_df['class']\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# List of classifiers\n",
        "classifiers = {\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Support Vector Machine\": SVC(),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Naive Bayes\": GaussianNB()\n",
        "}\n",
        "\n",
        "# Train and evaluate each classifier\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred, target_names=['edible', 'poisonous'])\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(report)\n"
      ],
      "metadata": {
        "id": "lYylqmpaQbnl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f016587-e258-4ddc-b994-4e792df96c23"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forest:\n",
            "Accuracy: 1.0000\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      edible       1.00      1.00      1.00       843\n",
            "   poisonous       1.00      1.00      1.00       782\n",
            "\n",
            "    accuracy                           1.00      1625\n",
            "   macro avg       1.00      1.00      1.00      1625\n",
            "weighted avg       1.00      1.00      1.00      1625\n",
            "\n",
            "\n",
            "Support Vector Machine:\n",
            "Accuracy: 0.9926\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      edible       0.99      1.00      0.99       843\n",
            "   poisonous       1.00      0.99      0.99       782\n",
            "\n",
            "    accuracy                           0.99      1625\n",
            "   macro avg       0.99      0.99      0.99      1625\n",
            "weighted avg       0.99      0.99      0.99      1625\n",
            "\n",
            "\n",
            "K-Nearest Neighbors:\n",
            "Accuracy: 0.9963\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      edible       1.00      0.99      1.00       843\n",
            "   poisonous       0.99      1.00      1.00       782\n",
            "\n",
            "    accuracy                           1.00      1625\n",
            "   macro avg       1.00      1.00      1.00      1625\n",
            "weighted avg       1.00      1.00      1.00      1625\n",
            "\n",
            "\n",
            "Logistic Regression:\n",
            "Accuracy: 0.9471\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      edible       0.95      0.95      0.95       843\n",
            "   poisonous       0.94      0.95      0.95       782\n",
            "\n",
            "    accuracy                           0.95      1625\n",
            "   macro avg       0.95      0.95      0.95      1625\n",
            "weighted avg       0.95      0.95      0.95      1625\n",
            "\n",
            "\n",
            "Decision Tree:\n",
            "Accuracy: 1.0000\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      edible       1.00      1.00      1.00       843\n",
            "   poisonous       1.00      1.00      1.00       782\n",
            "\n",
            "    accuracy                           1.00      1625\n",
            "   macro avg       1.00      1.00      1.00      1625\n",
            "weighted avg       1.00      1.00      1.00      1625\n",
            "\n",
            "\n",
            "Naive Bayes:\n",
            "Accuracy: 0.9218\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      edible       0.93      0.91      0.92       843\n",
            "   poisonous       0.91      0.93      0.92       782\n",
            "\n",
            "    accuracy                           0.92      1625\n",
            "   macro avg       0.92      0.92      0.92      1625\n",
            "weighted avg       0.92      0.92      0.92      1625\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 9"
      ],
      "metadata": {
        "id": "g-QZB90qQbp6"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate your model on at least three metrics. And Evaluation result as DataFrame at the end."
      ],
      "metadata": {
        "id": "QIwa9df4QbrY"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Load Mushroom dataset from CSV\n",
        "mushroom_df = pd.read_csv('/content/mushrooms.csv')\n",
        "\n",
        "# Encode categorical variables using LabelEncoder\n",
        "label_encoders = {}\n",
        "for column in mushroom_df.columns:\n",
        "    encoder = LabelEncoder()\n",
        "    mushroom_df[column] = encoder.fit_transform(mushroom_df[column])\n",
        "    label_encoders[column] = encoder\n",
        "\n",
        "# Separate features and labels\n",
        "X = mushroom_df.drop('class', axis=1)\n",
        "y = mushroom_df['class']\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# List of classifiers\n",
        "classifiers = {\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Support Vector Machine\": SVC(),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Naive Bayes\": GaussianNB()\n",
        "}\n",
        "\n",
        "# Initialize lists to store evaluation metrics\n",
        "evaluation_metrics = {\n",
        "    'Classifier': [],\n",
        "    'Accuracy': [],\n",
        "    'Precision': [],\n",
        "    'Recall': [],\n",
        "    'F1-score': []\n",
        "}\n",
        "\n",
        "# Train and evaluate each classifier\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred, target_names=['edible', 'poisonous'], output_dict=True)\n",
        "\n",
        "    # Store evaluation metrics\n",
        "    evaluation_metrics['Classifier'].append(name)\n",
        "    evaluation_metrics['Accuracy'].append(accuracy)\n",
        "    evaluation_metrics['Precision'].append(report['weighted avg']['precision'])\n",
        "    evaluation_metrics['Recall'].append(report['weighted avg']['recall'])\n",
        "    evaluation_metrics['F1-score'].append(report['weighted avg']['f1-score'])\n",
        "\n",
        "# Create DataFrame for evaluation results\n",
        "evaluation_df = pd.DataFrame(evaluation_metrics)\n",
        "\n",
        "# Display evaluation results\n",
        "print(\"Evaluation Results:\")\n",
        "print(evaluation_df)\n"
      ],
      "metadata": {
        "id": "taE-lMueQbtR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a228ca3a-4524-49bc-ee22-577084c3694e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results:\n",
            "               Classifier  Accuracy  Precision    Recall  F1-score\n",
            "0           Random Forest  1.000000   1.000000  1.000000  1.000000\n",
            "1  Support Vector Machine  0.992615   0.992687  0.992615  0.992613\n",
            "2     K-Nearest Neighbors  0.996308   0.996336  0.996308  0.996308\n",
            "3     Logistic Regression  0.947077   0.947098  0.947077  0.947081\n",
            "4           Decision Tree  1.000000   1.000000  1.000000  1.000000\n",
            "5             Naive Bayes  0.921846   0.922092  0.921846  0.921868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nJX_oiD0QbwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d7I7Gj4cQb0X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}